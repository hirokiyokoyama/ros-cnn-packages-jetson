#! /usr/bin/env python

import rospy
from openpose_ros.msg import PersonArray, Person
import cv2
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image
from geometry_msgs.msg import Pose, PoseStamped
import tf
import numpy as np
from dynamic_reconfigure.client import Client as ReconfClient
from labels import POSE_BODY_25_L2, POSE_BODY_25_L1
from std_srvs.srv import Empty

from camera_controller import CameraController
from pykalman import KalmanFilter
from _visualize import draw_peoplemsg

def ray_to_pose(p, v):
  pose = Pose()
  pose.position.x, pose.position.y, pose.position.z = p
  w = np.zeros(3)
  w[np.argmin(np.square(v))] = 1.
  w = np.cross(v, w)
  w /= np.linalg.norm(w)
  mat = np.zeros([4,4], dtype=np.float)
  mat[:3,0] = v
  mat[:3,1] = w
  mat[:3,2] = np.cross(v, w)
  mat[3,3] = 1.
  q = tf.transformations.quaternion_from_matrix(mat)
  pose.orientation.x, pose.orientation.y, pose.orientation.z, pose.orientation.w = q
  return pose

def img_cb(image_msg):
  global image
  try:
    image = bridge.imgmsg_to_cv2(image_msg, 'bgr8')
  except CvBridgeError as e:
    rospy.logerr(e)
    
def people_cb1(msg):
  global xavier_people
  xavier_people = msg
    
def people_cb2(msg):
  global tx2_people
  tx2_people = msg

class Track:
  _kf = KalmanFilter()
  
  def __init__(self, t, x):
    self._mean = np.array(list(x)+[0.]*2)
    self._cov = np.diag([1.]*2+[2.]*2)
    self._t = t
    self._obs_mat = np.eye(2,4)
    self._obs_cov = np.eye(2) * .2**2

  def _transition_matrices(self, dt):
    trans_mat = np.array([[1., 0., dt, 0.],
                          [0., 1., 0., dt],
                          [0., 0., 1., 0.],
                          [0., 0., 0., 1.]])
    trans_cov = np.diag([1.**2 * dt]*2+[4.**2 * dt]*2)
    return trans_mat, trans_cov

  def predict(self, t):
    self._mean, self._cov = self.get_prediction(t)
    self._t = t

  def get_prediction(self, t):
    dt = (t - self._t).to_sec()
    t_mat, t_cov = self._transition_matrices(dt)
    mean, cov = Track._kf.filter_update(self._mean, self._cov,
                                        transition_matrix=t_mat,
                                        transition_covariance=t_cov)
    return mean, cov
    
  def update(self, t, obs):
    dt = (t - self._t).to_sec()
    t_mat, t_cov = self._transition_matrices(dt)
    mean, cov = Track._kf.filter_update(self._mean, self._cov, obs,
                                        transition_matrix=t_mat,
                                        transition_covariance=t_cov,
                                        observation_matrix=self._obs_mat,
                                        observation_covariance=self._obs_cov)
    self._mean, self._cov = mean, cov
    self._t = t

class Tracker:
  def __init__(self):
    self._tracks = []
    
  def update(self, t, detections):
    if detections:
      if not self._tracks:
        detection = max(detections, key=lambda d: d[0][1])
        self._tracks.append(Track(t, detection[0]))
      else:
        track = self._tracks[0]
        mean, cov = track.get_prediction(t)
        detection = min(detections, key=lambda d: np.linalg.norm(d[0]-mean[:2]))
        track.update(t, detection[0])

    tracks = []
    for track in self._tracks:
      _, cov = track.get_prediction(t)
      if np.trace(cov[:2,:2])/2. < 8.:
        tracks.append(track)
    self._tracks = tracks
    
if __name__ == '__main__':
  rospy.init_node('openpose_tracker')

  cam = CameraController()
  tracker = Tracker()
  camera_target = None
  move_camera = False
  
  bridge = CvBridge()
  image = None
  xavier_people = None
  tx2_people = None

  reconf_tx2 = ReconfClient('openpose_tx2')
  reconf_tx2.update_configuration({
      'key_point_threshold': 0.3,
      'affinity_threshold': 0.1,
      'line_division': 3
  })
  reconf_xavier = ReconfClient('openpose_xavier')
  reconf_xavier.update_configuration({
      'key_point_threshold': 0.2,
      'affinity_threshold': 0.1,
      'line_division': 5
  })

  pose_pub = rospy.Publisher('person', PoseStamped, queue_size=1)
  pose2_pub = rospy.Publisher('camera_target', PoseStamped, queue_size=1)

  rospy.Subscriber('image', Image, img_cb,
                   queue_size=1, buff_size=1048576*8, tcp_nodelay=True)
  rospy.Subscriber('people_xavier', PersonArray, people_cb1,
                   queue_size=1, buff_size=1048576*8, tcp_nodelay=True)
  rospy.Subscriber('people_tx2', PersonArray, people_cb2,
                   queue_size=1, buff_size=1048576*8, tcp_nodelay=True)

  rate = rospy.Rate(10)
  prev_t = rospy.Time.now()
  while not rospy.is_shutdown():
    detections = []
    if tx2_people is not None and tx2_people.header.stamp > prev_t:
      for p in tx2_people.people:
        parts = {x.name: np.array([x.x * 640, x.y * 480]) \
                 for x in p.body_parts}
        if 'Neck' in parts and 'MidHip' in parts:
          center = (parts['Neck'] + parts['MidHip']) / 2.
        elif 'RShoulder' in parts and 'RElbow' in parts:
          center = (parts['RShoulder'] + parts['RElbow']) / 2.
        elif 'LShoulder' in parts and 'LElbow' in parts:
          center = (parts['LShoulder'] + parts['LElbow']) / 2.
        else:
          continue
        _, center = cam.from_pixel(center, 'base_link')
        detections.append((center[1:], parts)) # track on y-z plane
      prev_t = tx2_people.header.stamp
    if detections:
      tracker.update(prev_t, detections)
    else:
      tracker.update(rospy.Time.now(), [])

    p, _ = cam.from_pixel((0, 0), 'base_link')
    
    if tracker._tracks:
      track = tracker._tracks[0]
      t = rospy.Time.now()
      ps = PoseStamped()
      ps.header.stamp = t
      ps.header.frame_id = 'base_link'
      mean, cov = track.get_prediction(t)
      x = np.array([1., mean[0], mean[1]])
      ps.pose = ray_to_pose(p, x)
      pose_pub.publish(ps)

      if camera_target is None:
        camera_target = x
      else:
        camera_target[1] = camera_target[1]*0.8 + x[1]*0.2
        # sometimes tilt controller gives wrong value, so smooth z value
        camera_target[2] = camera_target[2]*0.95 + x[2]*0.05
    else:
      # if there is no target, camera moves to the initial pose
      if camera_target is not None:
        camera_target[1] = camera_target[1] * 0.8
        camera_target[2] = camera_target[1] * 0.8

    if camera_target is not None:
      ps = PoseStamped()
      ps.header.stamp = rospy.Time.now()
      ps.header.frame_id = 'base_link'
      ps.pose = ray_to_pose(p, camera_target)
      pose2_pub.publish(ps)

      if move_camera:
        cam.look_at(np.array(p) + camera_target,
                    source_frame='base_link')
    
    if image is not None:
      xavier_image = image.copy()
      tx2_image = image.copy()
      if xavier_people is not None:
        draw_peoplemsg(xavier_image, xavier_people)
      if tx2_people is not None:
        draw_peoplemsg(tx2_image, tx2_people)
      cv2.imshow('Xavier', np.uint8(xavier_image*0.5+image*0.5))
      cv2.imshow('TX2', np.uint8(tx2_image*0.5+image*0.5))
      
    key = cv2.waitKey(1)
    if key in range(ord('1'), ord('5')):
      stage = key - ord('0')
      rospy.set_param('/openpose_tx2/l1_stage', stage)
      rospy.ServiceProxy('initialize_network_tx2', Empty).call()
    if key == ord(' '):
      move_camera = not move_camera
    rate.sleep()
